{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc3c9e5",
   "metadata": {},
   "source": [
    "#          Project Name:      Facial Expression Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa9b3c",
   "metadata": {},
   "source": [
    "### OpenCV (Open Source Computer Vision Library) is an open-source computer vision and machine learning software library. which is built to provide a common infrastructure for machine learning algorithms and computer vision. It has thousands of optimized algorithms which can be used different purposes like detecting and recognizing faces, identifying objects and many more. We need it to take pictures using our webcam and some manipulation needed to be done in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "916c6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "437c102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('H.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aa7a8d",
   "metadata": {},
   "source": [
    "### Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b739bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "025043ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e393180b",
   "metadata": {},
   "source": [
    "### Deepface is a lightweight face recognition and facial attribute analysis (age, gender, emotion and race) framework for python. It is a hybrid face recognition framework wrapping state-of-the-art models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c7ba51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c2834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f35ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be6476",
   "metadata": {},
   "source": [
    "### Note: After executing below line two module of size 1 G.B. will install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9456b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = DeepFace.analyze(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01dccb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b895904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee32c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions['dominant_emotion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8ea88a",
   "metadata": {},
   "source": [
    "### Haar Cascade: It is an Object Detection Algorithm used to identify faces in an image or a real time video. The algorithm uses edge or line detection features proposed by Viola and Jones in their research paper “Rapid Object Detection using a Boosted Cascade of Simple Features” published in 2001. The algorithm is given a lot of positive images consisting of faces, and a lot of negative images not consisting of any face to train on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4d28607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9c40830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# faces = faceCascade.detectMultiScale(gray)\n",
    "# for(x,y,w,h) in faces:\n",
    "#     cv2.rectangle(img,(x,y),(x+w, y+h), (0,255,0),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcc0bdb",
   "metadata": {},
   "source": [
    "### cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32669a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# cv2.putText(img, predictions['dominant_emotion'],\n",
    "#            (200,200),\n",
    "#            font,7,\n",
    "#            (255,255,255),\n",
    "#            2,\n",
    "#            cv2.LINE_4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50032e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25f8edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c07546",
   "metadata": {},
   "source": [
    "### Note:  For realtime facial expression detection using laptop camera run below code.\n",
    "### This will open a GUI. Click on the button to open camera window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997fe63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "No face detected\n",
      "No face detected\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "No face detected\n",
      "No face detected\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "No face detected\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "No face detected\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "No face detected\n",
      "No face detected\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "No face detected\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "No face detected\n",
      "1/1 [==============================] - 10s 10s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter.font as tkFont\n",
    "\n",
    "\n",
    "\n",
    "window = Tk()\n",
    "window.title(\"Facial Expression, Age, Gender, Race Recoginiton\")\n",
    "window.resizable(width=False,height=False)\n",
    "window.configure(background='sienna1')\n",
    "\n",
    "helv36 = tkFont.Font(family=\"Helvetica\",size=15,weight=\"bold\")\n",
    "\n",
    "\n",
    "def faceExpressionVideo():\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    cap=cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "    while True:\n",
    "        try:\n",
    "            ret,frame = cap.read()\n",
    "            result = DeepFace.analyze(frame,actions=['emotion'])\n",
    "            gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = faceCascade.detectMultiScale(gray)\n",
    "            for(x,y,w,h) in faces:\n",
    "                cv2.rectangle(frame,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(frame, result['dominant_emotion'],\n",
    "                         (200,200),\n",
    "                          font,7,\n",
    "                          (255,255,255),\n",
    "                           2,\n",
    "                           cv2.LINE_4);\n",
    "            cv2.imshow('Original Video', frame)\n",
    "        except:\n",
    "            print(\"No face detected\")\n",
    "        \n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "myButton = Button(window,text='Facial Expression Recognition',command=faceExpressionVideo,font=helv36,pady=10, fg='bisque',bg='gray17',justify='center', width=40)\n",
    "# myButton.pack()\n",
    "\n",
    "def Age():\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    cap=cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            ret,frame = cap.read()\n",
    "            result = DeepFace.analyze(frame,actions=['age'])\n",
    "            gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = faceCascade.detectMultiScale(gray)\n",
    "            for(x,y,w,h) in faces:\n",
    "                cv2.rectangle(frame,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(frame, str(result['age']),\n",
    "                         (200,200),\n",
    "                          font,7,\n",
    "                          (255,255,255),\n",
    "                           2,\n",
    "                           cv2.LINE_4);\n",
    "            cv2.imshow('Original Video', frame)\n",
    "    \n",
    "        except:\n",
    "            print(\"No face detected\")\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "myButton1 = Button(window,text='Age Recognition ',command=Age, fg='bisque',bg='gray17',width=40,font=helv36,pady=10)\n",
    "# myButton1.pack()\n",
    "\n",
    "def Gender():\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    cap=cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            ret,frame = cap.read()\n",
    "            result = DeepFace.analyze(frame,actions=['gender'])\n",
    "            gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = faceCascade.detectMultiScale(gray)\n",
    "            for(x,y,w,h) in faces:\n",
    "                cv2.rectangle(frame,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(frame, result['gender'],\n",
    "                         (200,200),\n",
    "                          font,7,\n",
    "                          (255,255,255),\n",
    "                           2,\n",
    "                           cv2.LINE_4);\n",
    "            cv2.imshow('Original Video', frame)\n",
    "        except:\n",
    "            print(\"No face detected\")\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "myButton2 = Button(window,text='Gender Recognition',command=Gender, fg='bisque',bg='gray17',width=40,font=helv36,pady=10)\n",
    "# myButton2.pack()\n",
    "\n",
    "\n",
    "def Race():\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    cap=cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            ret,frame = cap.read()\n",
    "            result = DeepFace.analyze(frame,actions=['race'])\n",
    "            gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = faceCascade.detectMultiScale(gray)\n",
    "            for(x,y,w,h) in faces:\n",
    "                cv2.rectangle(frame,(x,y),(x+w, y+h),(0,255,0),2)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(frame, result['dominant_race'],\n",
    "                         (200,200),\n",
    "                          font,7,\n",
    "                          (255,255,255),\n",
    "                           2,\n",
    "                           cv2.LINE_4);\n",
    "            cv2.imshow('Original Video', frame)\n",
    "        except:\n",
    "            print(\"No face detected\")\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "myButton3 = Button(window,text='Race Recognition',command=Race, fg='bisque',bg='gray17',width=40,font=helv36,pady=10)\n",
    "# myButton3.pack()\n",
    "\n",
    "\n",
    "myButton.grid(row=5,column=0,padx=10,pady=10)\n",
    "myButton1.grid(row=6,column=0,padx=10,pady=10)\n",
    "myButton2.grid(row=7,column=0,padx=10,pady=10)\n",
    "myButton3.grid(row=8,column=0,padx=10,pady=10)\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020d4932",
   "metadata": {},
   "source": [
    "### The below code will provide result for facial expression recognition of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8954b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from deepface import DeepFace\n",
    "# from tkinter import *\n",
    "# import matplotlib.pyplot as plt\n",
    "# img=cv2.imread('e.jpg')\n",
    "# faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# faces = faceCascade.detectMultiScale(gray)\n",
    "# for(x,y,w,h) in faces:\n",
    "#     cv2.rectangle(img,(x,y),(x+w, y+h), (0,255,0),2)\n",
    "# predictions = DeepFace.analyze(img)\n",
    "# font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# cv2.putText(img, predictions['dominant_emotion'],\n",
    "#                 (200,200),\n",
    "#                 font,7,\n",
    "#                 (255,255,255),\n",
    "#                 2,\n",
    "#                 cv2.LINE_4);\n",
    "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d155d6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
